from fastapi import FastAPI, Depends
from sqlalchemy.orm import Session
from transformers import pipeline
from backend.database import SessionLocal, init_db, AnalyzedText

app = FastAPI()

# ðŸ”¹ Wczytanie modelu NLP do analizy fake newsÃ³w
nlp_model = pipeline("text-classification", model="mrm8488/bert-mini-fakenews")

# ðŸ”¹ Inicjalizacja bazy danych
init_db()


# ðŸ”¹ Funkcja do pobierania sesji bazy danych
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# ðŸ”¹ Model wejÅ›ciowy dla analizy tekstu
from pydantic import BaseModel


class TextAnalysisRequest(BaseModel):
    text: str


class AnalysisResponse(BaseModel):
    text: str
    fake_news_score: float
    source_reliability: float
    classification: str

@app.get("/")
def home():
    return {"message": "TruthGuard API dziaÅ‚a! SprawdÅº /docs"}

@app.post("/analyze_text", response_model=AnalysisResponse)
def analyze_text(request: TextAnalysisRequest, db: Session = Depends(get_db)):
    """
    Endpoint do analizy tekstu pod kÄ…tem fake newsÃ³w.
    Zwraca ocenÄ™ prawdopodobieÅ„stwa faÅ‚szywej informacji oraz ocenÄ™ wiarygodnoÅ›ci ÅºrÃ³dÅ‚a.
    """
    # Analiza NLP
    result = nlp_model(request.text)
    classification_label = result[0]['label']
    fake_news_score = result[0]['score'] if classification_label == "FAKE" else (1 - result[0]['score'])
    source_reliability = 1 - fake_news_score

    # ðŸ”¹ Zapisanie wyniku do bazy danych
    analyzed_text = AnalyzedText(
        text=request.text,
        fake_news_score=fake_news_score,
        source_reliability=source_reliability,
        classification=classification_label
    )
    db.add(analyzed_text)
    db.commit()

    return AnalysisResponse(
        text=request.text,
        fake_news_score=fake_news_score,
        source_reliability=source_reliability,
        classification=classification_label
    )
