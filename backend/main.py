from fastapi import FastAPI, Depends, HTTPException
from sqlalchemy.orm import Session
from transformers import pipeline
from pydantic import BaseModel
from newspaper import Article  # ðŸ“Œ Nowa biblioteka do pobierania treÅ›ci z URL
from backend.database import SessionLocal, init_db, AnalyzedText

app = FastAPI()

# ðŸ”¹ Wczytanie modelu NLP do analizy fake newsÃ³w
nlp_model = pipeline("text-classification", model="facebook/bart-large-mnli")

# ðŸ”¹ Inicjalizacja bazy danych
init_db()

# ðŸ”¹ Funkcja do pobierania sesji bazy danych
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ðŸ”¹ Model wejÅ›ciowy dla analizy tekstu i URL
class TextAnalysisRequest(BaseModel):
    text: str = None  # ðŸ“Œ Opcjonalnie uÅ¼ytkownik moÅ¼e podaÄ‡ tekst...
    url: str = None   # ðŸ“Œ ...lub URL do analizy

class AnalysisResponse(BaseModel):
    text: str
    fake_news_score: float
    source_reliability: float
    classification: str

@app.get("/")
def home():
    return {"message": "TruthGuard API dziaÅ‚a! SprawdÅº /docs"}

@app.post("/analyze_text", response_model=AnalysisResponse)
def analyze_text(request: TextAnalysisRequest, db: Session = Depends(get_db)):
    """
    Endpoint do analizy tekstu pod kÄ…tem fake newsÃ³w.
    ObsÅ‚uguje zarÃ³wno tekst jak i URL artykuÅ‚u.
    """

    if request.url:  # ðŸ“Œ JeÅ›li uÅ¼ytkownik podaÅ‚ URL â†’ pobieramy treÅ›Ä‡ strony
        try:
            article = Article(request.url)
            article.download()
            article.parse()
            request.text = article.text
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"BÅ‚Ä…d pobierania treÅ›ci z URL: {str(e)}")

    if not request.text:
        raise HTTPException(status_code=400, detail="Brak tekstu do analizy!")

    # ðŸ”¹ Analiza NLP
    result = nlp_model(request.text)
    classification_label = result[0]['label']
    fake_news_score = result[0]['score'] if classification_label == "FAKE" else (1 - result[0]['score'])
    source_reliability = 1 - fake_news_score

    # ðŸ”¹ Zapisanie wyniku do bazy danych
    analyzed_text = AnalyzedText(
        text=request.text[:500],  # ðŸ“Œ Ograniczamy dÅ‚ugoÅ›Ä‡ zapisanego tekstu
        fake_news_score=fake_news_score,
        source_reliability=source_reliability,
        classification=classification_label
    )
    db.add(analyzed_text)
    db.commit()

    return AnalysisResponse(
        text=request.text[:500],  # ðŸ“Œ Ograniczamy dÅ‚ugoÅ›Ä‡ zwracanego tekstu
        fake_news_score=fake_news_score,
        source_reliability=source_reliability,
        classification=classification_label
    )
